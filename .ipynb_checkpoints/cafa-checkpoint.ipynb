{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1bcc6192",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.neighbors import BallTree\n",
    "import faiss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a000cdd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.manifold import TSNE\n",
    "import matplotlib.pyplot as plt\n",
    "from Bio import SeqIO\n",
    "\n",
    "sequence_file = '/mnt/home/thamamsy/ceph/scrap/cafa/embeddings/Train/train_sequences.fasta'\n",
    "record_ids = []\n",
    "record_seqs = []\n",
    "\n",
    "with open(sequence_file) as handle:\n",
    "    for record in SeqIO.parse(handle, \"fasta\"):\n",
    "        record_ids.append(record.id)\n",
    "        record_seqs.append(str(record.seq))\n",
    "        \n",
    "lengths = [len(record_seqs[i]) for i in range(len(record_seqs))]\n",
    "record_df = pd.DataFrame({'Id': record_ids, 'Seq': record_seqs, 'Length': lengths})\n",
    "record_df_below_seq = record_df[record_df['Length'] < 2500]\n",
    "sequences = list(record_df_below_seq['Seq'].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cf6639f1",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "142246"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(record_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6be5d0dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#record_df_below_seq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6873c8e9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "140478"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(sequences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1bdf4077",
   "metadata": {},
   "outputs": [],
   "source": [
    "#record_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "135c55be",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_terms = pd.read_csv(\"/mnt/home/thamamsy/ceph/scrap/cafa/embeddings/Train/train_terms.tsv\", sep = '\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ed7e0eaf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(140478, 512)\n"
     ]
    }
   ],
   "source": [
    "train_embeddings = np.load('../../cafa/tm_vec_train.npy')\n",
    "#test_embeddings =\n",
    "# Now lets convert embeddings numpy array(train_embeddings) into pandas dataframe.\n",
    "column_num = train_embeddings.shape[1]\n",
    "train_df = pd.DataFrame(train_embeddings, columns = [\"Column_\" + str(i) for i in range(1, column_num+1)], \n",
    "                        index = record_df_below_seq.Id)\n",
    "print(train_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "48b7a8ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = train_df.sample(frac=1)\n",
    "train_df1 = df.iloc[:len(train_df) * 8//10]\n",
    "test_df1 = df.iloc[len(train_df) * 8//10:]\n",
    "# Convert the DataFrame to a NumPy array\n",
    "data_array = train_df1.to_numpy(dtype='float32')\n",
    "# Build the BallTree index\n",
    "index = faiss.IndexFlatL2(data_array.shape[1])  # L2 distance is used for the BallTree\n",
    "index.add(data_array)\n",
    "\n",
    "# Convert the test DataFrame to a NumPy array\n",
    "test_array = test_df1.to_numpy(dtype='float32')\n",
    "\n",
    "# Perform nearest neighbor search with the BallTree index\n",
    "k = 1  # Number of nearest neighbors to find\n",
    "distances, indices = index.search(test_array, k)\n",
    "\n",
    "# distances: array of shape (num_queries, k) containing the distances to the k nearest neighbors\n",
    "# indices: array of shape (num_queries, k) containing the indices of the k nearest neighbors in the original data\n",
    "\n",
    "# Now we have the nearest neighbors' indices and distances for each test sample.\n",
    "# access the corresponding data points in the original DataFrame as follows:\n",
    "nearest_neighbors_df = train_df1.iloc[indices[:, 0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "6360bd4e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<28096x22615 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 1111268 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sparse_matrix1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "986a98f5",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Found input variables with inconsistent numbers of samples: [633311936, 28096]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[16], line 57\u001b[0m\n\u001b[1;32m     54\u001b[0m flattened_similarities \u001b[38;5;241m=\u001b[39m similarities\u001b[38;5;241m.\u001b[39mflatten()\n\u001b[1;32m     56\u001b[0m \u001b[38;5;66;03m# Calculate AUPR using similarity scores and matrix2 as ground truth\u001b[39;00m\n\u001b[0;32m---> 57\u001b[0m aupr_score \u001b[38;5;241m=\u001b[39m \u001b[43maverage_precision_score\u001b[49m\u001b[43m(\u001b[49m\u001b[43mflattened_matrix2\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mflattened_similarities\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     58\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAUPR Score:\u001b[39m\u001b[38;5;124m\"\u001b[39m, aupr_score)\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.9/site-packages/sklearn/metrics/_ranking.py:234\u001b[0m, in \u001b[0;36maverage_precision_score\u001b[0;34m(y_true, y_score, average, pos_label, sample_weight)\u001b[0m\n\u001b[1;32m    227\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    228\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpos_label=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpos_label\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m is not a valid label. It should be \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    229\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mone of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpresent_labels\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    230\u001b[0m         )\n\u001b[1;32m    231\u001b[0m average_precision \u001b[38;5;241m=\u001b[39m partial(\n\u001b[1;32m    232\u001b[0m     _binary_uninterpolated_average_precision, pos_label\u001b[38;5;241m=\u001b[39mpos_label\n\u001b[1;32m    233\u001b[0m )\n\u001b[0;32m--> 234\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_average_binary_score\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    235\u001b[0m \u001b[43m    \u001b[49m\u001b[43maverage_precision\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_true\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_score\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maverage\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msample_weight\u001b[49m\n\u001b[1;32m    236\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.9/site-packages/sklearn/metrics/_base.py:75\u001b[0m, in \u001b[0;36m_average_binary_score\u001b[0;34m(binary_metric, y_true, y_score, average, sample_weight)\u001b[0m\n\u001b[1;32m     72\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;124m format is not supported\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(y_type))\n\u001b[1;32m     74\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m y_type \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbinary\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m---> 75\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mbinary_metric\u001b[49m\u001b[43m(\u001b[49m\u001b[43my_true\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_score\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msample_weight\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     77\u001b[0m check_consistent_length(y_true, y_score, sample_weight)\n\u001b[1;32m     78\u001b[0m y_true \u001b[38;5;241m=\u001b[39m check_array(y_true)\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.9/site-packages/sklearn/metrics/_ranking.py:207\u001b[0m, in \u001b[0;36maverage_precision_score.<locals>._binary_uninterpolated_average_precision\u001b[0;34m(y_true, y_score, pos_label, sample_weight)\u001b[0m\n\u001b[1;32m    204\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_binary_uninterpolated_average_precision\u001b[39m(\n\u001b[1;32m    205\u001b[0m     y_true, y_score, pos_label\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m, sample_weight\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    206\u001b[0m ):\n\u001b[0;32m--> 207\u001b[0m     precision, recall, _ \u001b[38;5;241m=\u001b[39m \u001b[43mprecision_recall_curve\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    208\u001b[0m \u001b[43m        \u001b[49m\u001b[43my_true\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_score\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpos_label\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpos_label\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msample_weight\u001b[49m\n\u001b[1;32m    209\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    210\u001b[0m     \u001b[38;5;66;03m# Return the step function integral\u001b[39;00m\n\u001b[1;32m    211\u001b[0m     \u001b[38;5;66;03m# The following works because the last entry of precision is\u001b[39;00m\n\u001b[1;32m    212\u001b[0m     \u001b[38;5;66;03m# guaranteed to be 1, as returned by precision_recall_curve\u001b[39;00m\n\u001b[1;32m    213\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;241m-\u001b[39mnp\u001b[38;5;241m.\u001b[39msum(np\u001b[38;5;241m.\u001b[39mdiff(recall) \u001b[38;5;241m*\u001b[39m np\u001b[38;5;241m.\u001b[39marray(precision)[:\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m])\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.9/site-packages/sklearn/metrics/_ranking.py:878\u001b[0m, in \u001b[0;36mprecision_recall_curve\u001b[0;34m(y_true, probas_pred, pos_label, sample_weight)\u001b[0m\n\u001b[1;32m    797\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mprecision_recall_curve\u001b[39m(y_true, probas_pred, \u001b[38;5;241m*\u001b[39m, pos_label\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, sample_weight\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m    798\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Compute precision-recall pairs for different probability thresholds.\u001b[39;00m\n\u001b[1;32m    799\u001b[0m \n\u001b[1;32m    800\u001b[0m \u001b[38;5;124;03m    Note: this implementation is restricted to the binary classification task.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    876\u001b[0m \u001b[38;5;124;03m    array([0.1 , 0.35, 0.4 , 0.8 ])\u001b[39;00m\n\u001b[1;32m    877\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 878\u001b[0m     fps, tps, thresholds \u001b[38;5;241m=\u001b[39m \u001b[43m_binary_clf_curve\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    879\u001b[0m \u001b[43m        \u001b[49m\u001b[43my_true\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprobas_pred\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpos_label\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpos_label\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msample_weight\u001b[49m\n\u001b[1;32m    880\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    882\u001b[0m     ps \u001b[38;5;241m=\u001b[39m tps \u001b[38;5;241m+\u001b[39m fps\n\u001b[1;32m    883\u001b[0m     \u001b[38;5;66;03m# Initialize the result array with zeros to make sure that precision[ps == 0]\u001b[39;00m\n\u001b[1;32m    884\u001b[0m     \u001b[38;5;66;03m# does not contain uninitialized values.\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.9/site-packages/sklearn/metrics/_ranking.py:751\u001b[0m, in \u001b[0;36m_binary_clf_curve\u001b[0;34m(y_true, y_score, pos_label, sample_weight)\u001b[0m\n\u001b[1;32m    748\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (y_type \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbinary\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m (y_type \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmulticlass\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m pos_label \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m)):\n\u001b[1;32m    749\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;124m format is not supported\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(y_type))\n\u001b[0;32m--> 751\u001b[0m \u001b[43mcheck_consistent_length\u001b[49m\u001b[43m(\u001b[49m\u001b[43my_true\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_score\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    752\u001b[0m y_true \u001b[38;5;241m=\u001b[39m column_or_1d(y_true)\n\u001b[1;32m    753\u001b[0m y_score \u001b[38;5;241m=\u001b[39m column_or_1d(y_score)\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.9/site-packages/sklearn/utils/validation.py:397\u001b[0m, in \u001b[0;36mcheck_consistent_length\u001b[0;34m(*arrays)\u001b[0m\n\u001b[1;32m    395\u001b[0m uniques \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39munique(lengths)\n\u001b[1;32m    396\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(uniques) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m--> 397\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    398\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFound input variables with inconsistent numbers of samples: \u001b[39m\u001b[38;5;132;01m%r\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    399\u001b[0m         \u001b[38;5;241m%\u001b[39m [\u001b[38;5;28mint\u001b[39m(l) \u001b[38;5;28;01mfor\u001b[39;00m l \u001b[38;5;129;01min\u001b[39;00m lengths]\n\u001b[1;32m    400\u001b[0m     )\n",
      "\u001b[0;31mValueError\u001b[0m: Found input variables with inconsistent numbers of samples: [633311936, 28096]"
     ]
    }
   ],
   "source": [
    "# train_terms -- nearest neighbors for testing\n",
    "train_terms = pd.read_csv(\"/mnt/home/thamamsy/ceph/scrap/cafa/embeddings/Train/train_terms.tsv\", sep = '\\t')\n",
    "selected_ids = nearest_neighbors_df.index\n",
    "train_terms.set_index('EntryID', inplace=True)\n",
    "nearest_neighbors = train_terms.loc[selected_ids]\n",
    "nearest_neighbors = nearest_neighbors.drop('aspect', axis=1)\n",
    "# Use pivot_table to create the new DataFrame\n",
    "new_nearest_neighbors = nearest_neighbors.pivot_table(index='Id', columns='term', aggfunc=lambda x: 1, fill_value=0)\n",
    "\n",
    "#test_df1\n",
    "train_terms = pd.read_csv(\"/mnt/home/thamamsy/ceph/scrap/cafa/embeddings/Train/train_terms.tsv\", sep = '\\t')\n",
    "selected_ids = test_df1.index\n",
    "train_terms.set_index('EntryID', inplace=True)\n",
    "test_df1_labels = train_terms.loc[selected_ids]\n",
    "test_df1_labels = test_df1_labels.drop('aspect', axis=1)\n",
    "# Use pivot_table to create the new DataFrame\n",
    "new_test_df1_labels = test_df1_labels.pivot_table(index='Id', columns='term', aggfunc=lambda x: 1, fill_value=0)\n",
    "\n",
    "test_df1_Go = pd.DataFrame(new_test_df1_labels, index=test_df1.index)\n",
    "nearest_neighbors_Go = pd.DataFrame(new_nearest_neighbors, index=nearest_neighbors_df.index)\n",
    "\n",
    "#AUPR for multi-label output\n",
    "nearest_neighbors_Go_new_index = nearest_neighbors_Go.reset_index(drop=True)\n",
    "nearest_neighbors_Go_new_index.index = nearest_neighbors_Go_new_index.index + 1\n",
    "#test_df1_Go\n",
    "test_df1_Go_new_index = test_df1_Go.reset_index(drop=True)\n",
    "test_df1_Go_new_index.index = test_df1_Go_new_index.index + 1\n",
    "\n",
    "from scipy.sparse import csr_matrix\n",
    "from sklearn.metrics import average_precision_score\n",
    "\n",
    "sparse_matrix1 = csr_matrix(nearest_neighbors_Go_new_index)\n",
    "sparse_matrix2 = csr_matrix(test_df1_Go_new_index)\n",
    "\n",
    "# Check the shapes of the matrices\n",
    "shape1 = sparse_matrix1.shape\n",
    "shape2 = sparse_matrix2.shape\n",
    "\n",
    "# If the shapes are different, resize the matrices to the same shape\n",
    "if shape1 != shape2:\n",
    "    # Choose the common shape that both matrices will be resized to\n",
    "    common_shape = (max(shape1[0], shape2[0]), max(shape1[1], shape2[1]))\n",
    "\n",
    "    # Resize the matrices to the common shape\n",
    "    sparse_matrix1.resize(common_shape)\n",
    "    sparse_matrix2.resize(common_shape)\n",
    "\n",
    "# Calculate the similarity scores using the k-NN algorithm and assume they are stored in the \"similarities\" variable\n",
    "similarities = np.exp(-distances)\n",
    "\n",
    "# Flatten the matrices and similarity scores for AUPR calculation\n",
    "flattened_matrix1 = sparse_matrix1.toarray().flatten()\n",
    "flattened_matrix2 = sparse_matrix2.toarray().flatten()\n",
    "flattened_similarities = similarities.flatten()\n",
    "\n",
    "# Calculate AUPR using similarity scores and matrix2 as ground truth\n",
    "aupr_score = average_precision_score(flattened_matrix2, flattened_similarities)\n",
    "print(\"AUPR Score:\", aupr_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "666cd396",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Shape of flattened_matrix2:\", flattened_matrix2.shape)\n",
    "print(\"Shape of flattened_similarities:\", flattened_similarities.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8115ff15",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from scipy.sparse import csr_matrix\n",
    "from sklearn.metrics import average_precision_score\n",
    "\n",
    "sparse_matrix1 = csr_matrix(nearest_neighbors_Go_new_index)\n",
    "sparse_matrix2 = csr_matrix(test_df1_Go_new_index)\n",
    "\n",
    "# Check the shapes of the matrices\n",
    "shape1 = sparse_matrix1.shape\n",
    "shape2 = sparse_matrix2.shape\n",
    "\n",
    "# If the shapes are different, resize the matrices to the same shape\n",
    "if shape1 != shape2:\n",
    "    # Choose the common shape that both matrices will be resized to\n",
    "    common_shape = (max(shape1[0], shape2[0]), max(shape1[1], shape2[1]))\n",
    "\n",
    "    # Resize the matrices to the common shape\n",
    "    sparse_matrix1.resize(common_shape)\n",
    "    sparse_matrix2.resize(common_shape)\n",
    "\n",
    "# Calculate the similarity scores using the k-NN algorithm and assume they are stored in the \"similarities\" variable\n",
    "similarities = np.exp(-distances)\n",
    "\n",
    "# Flatten the matrices and similarity scores for AUPR calculation\n",
    "flattened_matrix1 = sparse_matrix1.toarray().flatten()\n",
    "flattened_matrix2 = sparse_matrix2.toarray().flatten()\n",
    "flattened_similarities = similarities.flatten()\n",
    "\n",
    "# Calculate AUPR using similarity scores and matrix2 as ground truth\n",
    "aupr_score = average_precision_score(flattened_matrix2, flattened_matrix2)\n",
    "print(\"AUPR Score:\", aupr_score)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
