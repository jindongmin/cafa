{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1bcc6192",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.neighbors import BallTree\n",
    "import faiss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a000cdd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.manifold import TSNE\n",
    "import matplotlib.pyplot as plt\n",
    "from Bio import SeqIO\n",
    "\n",
    "sequence_file = '/mnt/home/thamamsy/ceph/scrap/cafa/embeddings/Train/train_sequences.fasta'\n",
    "record_ids = []\n",
    "record_seqs = []\n",
    "\n",
    "with open(sequence_file) as handle:\n",
    "    for record in SeqIO.parse(handle, \"fasta\"):\n",
    "        record_ids.append(record.id)\n",
    "        record_seqs.append(str(record.seq))\n",
    "        \n",
    "lengths = [len(record_seqs[i]) for i in range(len(record_seqs))]\n",
    "record_df = pd.DataFrame({'Id': record_ids, 'Seq': record_seqs, 'Length': lengths})\n",
    "record_df_below_seq = record_df[record_df['Length'] < 2500]\n",
    "sequences = list(record_df_below_seq['Seq'].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cf6639f1",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "142246"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(record_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6be5d0dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#record_df_below_seq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6873c8e9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "140478"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(sequences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1bdf4077",
   "metadata": {},
   "outputs": [],
   "source": [
    "#record_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "135c55be",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_terms = pd.read_csv(\"/mnt/home/thamamsy/ceph/scrap/cafa/embeddings/Train/train_terms.tsv\", sep = '\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ed7e0eaf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(140478, 512)\n"
     ]
    }
   ],
   "source": [
    "train_embeddings = np.load('../cafa/tm_vec_train.npy')\n",
    "#test_embeddings =\n",
    "# Now lets convert embeddings numpy array(train_embeddings) into pandas dataframe.\n",
    "column_num = train_embeddings.shape[1]\n",
    "train_df = pd.DataFrame(train_embeddings, columns = [\"Column_\" + str(i) for i in range(1, column_num+1)], \n",
    "                        index = record_df_below_seq.Id)\n",
    "print(train_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "48b7a8ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = train_df.sample(frac=1)\n",
    "train_df1 = df.iloc[:len(train_df) * 8//10]\n",
    "test_df1 = df.iloc[len(train_df) * 8//10:]\n",
    "# Convert the DataFrame to a NumPy array\n",
    "data_array = train_df1.to_numpy(dtype='float32')\n",
    "# Build the BallTree index\n",
    "index = faiss.IndexFlatL2(data_array.shape[1])  # L2 distance is used for the BallTree\n",
    "index.add(data_array)\n",
    "\n",
    "# Convert the test DataFrame to a NumPy array\n",
    "test_array = test_df1.to_numpy(dtype='float32')\n",
    "\n",
    "# Perform nearest neighbor search with the BallTree index\n",
    "k = 1  # Number of nearest neighbors to find\n",
    "distances, indices = index.search(test_array, k)\n",
    "\n",
    "# distances: array of shape (num_queries, k) containing the distances to the k nearest neighbors\n",
    "# indices: array of shape (num_queries, k) containing the indices of the k nearest neighbors in the original data\n",
    "\n",
    "# Now we have the nearest neighbors' indices and distances for each test sample.\n",
    "# access the corresponding data points in the original DataFrame as follows:\n",
    "nearest_neighbors_df = train_df1.iloc[indices[:, 0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "6360bd4e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<28096x22615 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 1111268 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sparse_matrix1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "986a98f5",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "The truth value of an array with more than one element is ambiguous. Use a.any() or a.all()",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[78], line 40\u001b[0m\n\u001b[1;32m     37\u001b[0m shape2 \u001b[38;5;241m=\u001b[39m sparse_matrix2\u001b[38;5;241m.\u001b[39mshape\n\u001b[1;32m     39\u001b[0m \u001b[38;5;66;03m# If the shapes are different, resize the matrices to the same shape\u001b[39;00m\n\u001b[0;32m---> 40\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m similarities \u001b[38;5;241m!=\u001b[39m shape2:\n\u001b[1;32m     41\u001b[0m     \u001b[38;5;66;03m# Choose the common shape that both matrices will be resized to\u001b[39;00m\n\u001b[1;32m     42\u001b[0m     common_shape \u001b[38;5;241m=\u001b[39m (\u001b[38;5;28mmax\u001b[39m(similarities[\u001b[38;5;241m0\u001b[39m], shape2[\u001b[38;5;241m0\u001b[39m]), \u001b[38;5;28mmax\u001b[39m(similarities[\u001b[38;5;241m1\u001b[39m], shape2[\u001b[38;5;241m1\u001b[39m]))\n\u001b[1;32m     44\u001b[0m     \u001b[38;5;66;03m# Resize the matrices to the common shape\u001b[39;00m\n",
      "\u001b[0;31mValueError\u001b[0m: The truth value of an array with more than one element is ambiguous. Use a.any() or a.all()"
     ]
    }
   ],
   "source": [
    "# train_terms -- nearest neighbors for testing\n",
    "train_terms = pd.read_csv(\"/mnt/home/thamamsy/ceph/scrap/cafa/embeddings/Train/train_terms.tsv\", sep = '\\t')\n",
    "selected_ids = nearest_neighbors_df.index\n",
    "train_terms.set_index('EntryID', inplace=True)\n",
    "nearest_neighbors = train_terms.loc[selected_ids]\n",
    "nearest_neighbors = nearest_neighbors.drop('aspect', axis=1)\n",
    "# Use pivot_table to create the new DataFrame\n",
    "new_nearest_neighbors = nearest_neighbors.pivot_table(index='Id', columns='term', aggfunc=lambda x: 1, fill_value=0)\n",
    "\n",
    "#test_df1\n",
    "train_terms = pd.read_csv(\"/mnt/home/thamamsy/ceph/scrap/cafa/embeddings/Train/train_terms.tsv\", sep = '\\t')\n",
    "selected_ids = test_df1.index\n",
    "train_terms.set_index('EntryID', inplace=True)\n",
    "test_df1_labels = train_terms.loc[selected_ids]\n",
    "test_df1_labels = test_df1_labels.drop('aspect', axis=1)\n",
    "# Use pivot_table to create the new DataFrame\n",
    "new_test_df1_labels = test_df1_labels.pivot_table(index='Id', columns='term', aggfunc=lambda x: 1, fill_value=0)\n",
    "\n",
    "test_df1_Go = pd.DataFrame(new_test_df1_labels, index=test_df1.index)\n",
    "nearest_neighbors_Go = pd.DataFrame(new_nearest_neighbors, index=nearest_neighbors_df.index)\n",
    "\n",
    "#AUPR for multi-label output\n",
    "nearest_neighbors_Go_new_index = nearest_neighbors_Go.reset_index(drop=True)\n",
    "nearest_neighbors_Go_new_index.index = nearest_neighbors_Go_new_index.index + 1\n",
    "#test_df1_Go\n",
    "test_df1_Go_new_index = test_df1_Go.reset_index(drop=True)\n",
    "test_df1_Go_new_index.index = test_df1_Go_new_index.index + 1\n",
    "\n",
    "from scipy.sparse import csr_matrix\n",
    "from sklearn.metrics import average_precision_score\n",
    "\n",
    "sparse_matrix1 = csr_matrix(nearest_neighbors_Go_new_index)\n",
    "sparse_matrix2 = csr_matrix(test_df1_Go_new_index)\n",
    "\n",
    "# Check the shapes of the matrices\n",
    "shape1 = sparse_matrix1.shape\n",
    "shape2 = sparse_matrix2.shape\n",
    "\n",
    "# If the shapes are different, resize the matrices to the same shape\n",
    "if similarities != shape2:\n",
    "    # Choose the common shape that both matrices will be resized to\n",
    "    common_shape = (max(similarities[0], shape2[0]), max(similarities[1], shape2[1]))\n",
    "\n",
    "    # Resize the matrices to the common shape\n",
    "    similarities.resize(common_shape)\n",
    "    sparse_matrix2.resize(common_shape)\n",
    "\n",
    "# Calculate the similarity scores using the k-NN algorithm and assume they are stored in the \"similarities\" variable\n",
    "similarities = np.exp(-distances)\n",
    "\n",
    "# Flatten the matrices and similarity scores for AUPR calculation\n",
    "flattened_matrix1 = sparse_matrix1.toarray().flatten()\n",
    "flattened_matrix2 = sparse_matrix2.toarray().flatten()\n",
    "flattened_similarities = similarities.flatten()\n",
    "\n",
    "# Calculate AUPR using similarity scores and matrix2 as ground truth\n",
    "aupr_score = average_precision_score(flattened_matrix2, flattened_similarities)\n",
    "print(\"AUPR Score:\", aupr_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "666cd396",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of flattened_matrix2: (635391040,)\n",
      "Shape of flattened_similarities: (28096,)\n"
     ]
    }
   ],
   "source": [
    "print(\"Shape of flattened_matrix2:\", flattened_matrix2.shape)\n",
    "print(\"Shape of flattened_similarities:\", flattened_similarities.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "8115ff15",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUPR Score: 0.0017583177259355017\n"
     ]
    }
   ],
   "source": [
    "from scipy.sparse import csr_matrix\n",
    "from sklearn.metrics import average_precision_score\n",
    "\n",
    "sparse_matrix1 = csr_matrix(nearest_neighbors_Go_new_index)\n",
    "sparse_matrix2 = csr_matrix(test_df1_Go_new_index)\n",
    "\n",
    "# Check the shapes of the matrices\n",
    "shape1 = sparse_matrix1.shape\n",
    "shape2 = sparse_matrix2.shape\n",
    "\n",
    "# If the shapes are different, resize the matrices to the same shape\n",
    "if shape1 != shape2:\n",
    "    # Choose the common shape that both matrices will be resized to\n",
    "    common_shape = (max(shape1[0], shape2[0]), max(shape1[1], shape2[1]))\n",
    "\n",
    "    # Resize the matrices to the common shape\n",
    "    sparse_matrix1.resize(common_shape)\n",
    "    sparse_matrix2.resize(common_shape)\n",
    "\n",
    "# Calculate the similarity scores using the k-NN algorithm and assume they are stored in the \"similarities\" variable\n",
    "similarities = np.exp(-distances)\n",
    "\n",
    "# Flatten the matrices and similarity scores for AUPR calculation\n",
    "flattened_matrix1 = sparse_matrix1.toarray().flatten()\n",
    "flattened_matrix2 = sparse_matrix2.toarray().flatten()\n",
    "flattened_similarities = similarities.flatten()\n",
    "\n",
    "# Calculate AUPR using similarity scores and matrix2 as ground truth\n",
    "aupr_score = average_precision_score(flattened_matrix2, flattened_matrix2)\n",
    "print(\"AUPR Score:\", aupr_score)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
